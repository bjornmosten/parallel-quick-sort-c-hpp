\documentclass{report}

\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{High Performance and Parallell Computing}\\Assignment 3}
\author{\huge{Bj√∂rn Mosten}}
\date{}

\begin{document}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak

\chapter{}
\setcounter{section}{1}
\section{Introduction}
The goal of this project was to create a well-performing quick-sort process that scales well with multiple threads.
Quick-sort is a divide and conquer algorithm that sorts an array of elements by (pseudo-, or actually) recursively partitioning the given array into two parts. Before partitioning, a pivot value is selected according to some metric (preferably a value as close to the middle middle as possible). 
The array is then split into two parts, one part containing all values lower than the pivot value and one part containing all values higher than the pivot value. The pivot value is then placed in the middle, with the lower part to the left of the pivot and the upper part to the right of the pivot. 
This process is then repeated on each part util the parts are of size 1, at which point the array is necessarily sorted.

Quick-sort was initially created with only a single thread in mind, but it is possible to parallelize the algorithm by having each thread sort its own part of the array and, 
then combining the results into a single array.
It was written in C and utilizes the OpenMP API for parallelization.



\subsection{Hardware}
CPU: AMD Ryzen 7 3700X 8-Core Processor, with a maximum clock speed of 3.6 GHz. It has 256 KB of L1i-cache, 256 KB of L1d-cache, 4 MB of L2-cache and 32 MB of L3-cache. It has 8 cores and 2 threads per core.
RAM: 32 GB of DDR4 RAM.

\section{Solution}
\subsection{Data Structures}
Each thread is given a struct containing the following data:
\begin{itemize}
    \item \texttt{int * data} - The data to be sorted.
    \item \texttt{int * data\_free} - A pointer to the start of the data array. This is often, but not always, the same as \textit{data}.
    \item \texttt{int * new\_data} - Data array to be used when merging. Combines the data from \textit{tmp\_data} from another thread and 
        \textit{data} from the current thread.
    \item \texttt{int * tmp\_data} - Temporary data array containing the data that is to be merged into another thread.
    \item \texttt{int data\_n} - The number of elements in the data array.
    \item \texttt{int tmp\_data\_n} - The number of elements in the tmp\_data array.
\end{itemize}

\subsection{Algorithm}
Each thread is given an equal amount of data to sort. Initially, each thread sorts its own data using the default C qsort function. 
All threads are put into a single group and common pivot point is calculated by taking the average of the median values of all threads in each group.
\section{Optimization Techniques}
\subsection{Parallelization}
Parallelization was done with OpenMP. 

Each thread is given 1/N of the data to sort, where N is the number of threads.
Initially, each thread sorts its own data using the default C qsort function. A group of N threads is created and each thread is given a 'partner' in said group. Each pair consists of one 'lower' part and one 'upper' part. 
Each thread calculates the average of the medians in its given group. This calculation may not be necessary, but by calculating it in each threads allows us to remove the overhead of having to communicate the median values between threads. 
Each thread then partitions its data into two parts, one part containing all values lower than the average of the medians and one part containing all values higher than the average of the medians. In each pair of threads,
the thread with a higher thread id is given the upper part part of its partner thread, and the thread with a lower thread id is given the lower part of its partner thread.

At this point, the group now consists of N/2 threads containing values above the average of the medians and N/2 threads containing values below the average of the medians. 
The process can now be repeated recursively, splitting the group into smaller and smaller groups until each group contains only a single thread.




\subsection{Loop Unrolling}


\section{Compilator}
GCC 11 was used for compilation with the following flags:
\begin{lstlisting}
    -Ofast 
    -flto 
    -ftree-vectorize 
    -march=native 
    -mtune=native
    -fopenmp 
    -funroll-loops  
    -mno-vzeroupper 
    -fno-trapping-math 
    -fno-signaling-nans 
    -funsafe-math-optimizations
\end{lstlisting}

\section{End Results}




\includegraphics[width=\textwidth]{openmp.png}


\bibliographystyle{plain}
\bibliography{bib}

\end{document}
